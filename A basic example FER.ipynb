{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06bbdd5",
   "metadata": {},
   "source": [
    "# Important installation procedures. \n",
    "\n",
    "\n",
    "## Necessary python packages \n",
    "\n",
    "- pandas\n",
    "- torch\n",
    "- matplotlib\n",
    "\n",
    "You can use conda (recommended) or pip to do this.\n",
    "\n",
    "\n",
    "## Download the data \n",
    "Save it in the project folder </br>  \n",
    "https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data?select=icml_face_data.csv\n",
    "\n",
    "\n",
    "\n",
    "## Credits\n",
    "\n",
    "https://www.kaggle.com/alinaspasskaya/lab-2-face-emotion-classification-with-mlp </br>\n",
    "https://www.kaggle.com/sharadhaviswanathan/imageclassification-facialexpression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cefc19b",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4240d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2538a4",
   "metadata": {},
   "source": [
    "## Obtaining and Preprocessing the data\n",
    "\n",
    "In data preparation the first step will be getting the train, validation and test data and this applies across all the modalities.Preprocessing the dataset varies based on both dataset and the model architecture in place. For example, some model architecture requries certain image dimensions. \n",
    "\n",
    "\n",
    "####  Currently in this code we have not done any special preprocessing. Some of the recommended methods that you can check out are to improve the model are\n",
    "\n",
    "1. Random data augmentation\n",
    "2. Oversampling or Undersampling the data to makeup for the imbalance in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454051c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/icml_face_data.csv\"\n",
    "data = pd.read_csv(data_path) ## Grayscale images\n",
    "\n",
    "emotion_labels = ['Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise', 'Neutral']\n",
    "\n",
    "\n",
    "def parse_data(data):\n",
    "    \n",
    "    image_array = np.zeros(shape=(len(data), 48, 48)) # 1\n",
    "    image_label = np.array(list(map(int, data['emotion'])))\n",
    "    \n",
    "    for i, row in enumerate(data.index):\n",
    "        \n",
    "        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48)) # 1\n",
    "        image_array[i] = image\n",
    "        \n",
    "        \n",
    "    return image_array, image_label\n",
    "\n",
    "# Splitting the data into train, validation and testing set thanks to Usage column\n",
    "train_imgs, train_lbls = parse_data(data[data[\" Usage\"] == \"Training\"])\n",
    "val_imgs, val_lbls = parse_data(data[data[\" Usage\"] == \"PrivateTest\"])\n",
    "test_imgs, test_lbls = parse_data(data[data[\" Usage\"] == \"PublicTest\"])\n",
    "\n",
    "\n",
    "\n",
    "def sample_plot(x,y=None):    #x, y are numpy arrays\n",
    "    n = 10\n",
    "    samples = random.sample(range(x.shape[0]),n)\n",
    "    fig, axs = plt.subplots(2,5, figsize=(25,5))\n",
    "    ax = axs.ravel()\n",
    "    for i in range(n):\n",
    "        ax[i].imshow(x[samples[i],:,:], cmap=plt.get_cmap('gray'))\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_yticks([])\n",
    "        if y is not None:\n",
    "            ax[i].set_title(emotion_labels[y[samples[i]]])\n",
    "\n",
    "sample_plot(train_imgs,train_lbls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca95a9",
   "metadata": {},
   "source": [
    "## Structuring the dataset to pass it through a dataloader in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FER2013_Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,imgs,labels):\n",
    "\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img = torch.FloatTensor(self.imgs[index])\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "\n",
    "    \n",
    "train_dataset = FER2013_Dataset(train_imgs, train_lbls)\n",
    "valid_dataset = FER2013_Dataset(val_imgs, val_lbls)\n",
    "test_dataset = FER2013_Dataset(test_imgs, test_lbls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d61f583",
   "metadata": {},
   "source": [
    "## Defining the model architecture - A simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47fe9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    # define model layers\n",
    "    def __init__(self,img_size,output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten_img_size = img_size[0]*img_size[1]\n",
    "        self.flatten_fc = nn.Linear(self.flatten_img_size,120)\n",
    "        self.fc1 = nn.Linear(120,84)\n",
    "        self.output_layer = nn.Linear(84,output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, img):\n",
    "        img = img.view(-1,self.flatten_img_size) ## img size: Batch size x 48 x 48 --> Batch size x 2304\n",
    "        \n",
    "        embedding = self.flatten_fc(img) ## Batch size x 2304 --> Batch size x 120\n",
    "        \n",
    "        embedding = F.relu(embedding) ## Applying non-linear activation after a dense layer\n",
    "        \n",
    "        embedding =  F.relu(self.fc1(embedding))  ## Batch size x  120--> Batch size x 84\n",
    "        \n",
    "        logits =  self.output_layer(embedding)    ## Batch size x 84 --> Batch size x output size\n",
    "         \n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3422ad98",
   "metadata": {},
   "source": [
    "## Defining the model architecture - A basic CNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN_Net, self).__init__()\n",
    "\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1,6,1) ## in channel, out channel\n",
    "        self.conv2 = nn.Conv2d(6,16,6) ## in channel, out channel\n",
    "   \n",
    "        self.fc1 = nn.Linear(16*9*9, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac56e13",
   "metadata": {},
   "source": [
    " <font color='red'> <b> >> CHANGE THE PARAMETERS HERE AND RE-RUN FROM THIS CELL</font>\n",
    "\n",
    "## Getting things ready for training\n",
    "\n",
    "A fairly general checklist,\n",
    "\n",
    "1. Choose the model\n",
    "2. Initialise the data loaders using the created dataset\n",
    "3. Loss function\n",
    "4. Optimiser\n",
    "5. Learning rate scheduler (You can try adding this)\n",
    "6. Hyperparmeter settings\n",
    " \n",
    "\n",
    "###### Do note that the choice of the items in this checklist is highly dependant on your choice of task, model and data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepoch = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "model_arch = \"mlp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3731b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SET THE SEED FOR GETTING THE SAME RESULTS AGAIN\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# MODEL\n",
    "if model_arch == \"mlp\":\n",
    "    model = MLP((48,48),7)\n",
    "elif model_arch == \"cnn_net\":\n",
    "    model = CNN_Net()\n",
    "    \n",
    "# DATA LOADER\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = batch_size,shuffle= True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,batch_size = 1,shuffle= False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size = 1,shuffle= False)\n",
    "\n",
    "# LOSS\n",
    "loss_fn = nn.CrossEntropyLoss()  ## applies softmax to the logits before computing the loss \n",
    "\n",
    "\n",
    "# OPTIMISER\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9015fbba",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The training dataset is divided into batches by the dataloader. The weights of the model are updated after learning every batch. Here, we choose the best model based on the validation performance (accuracy). The saved best model is used to get the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27905e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(nepoch):  # loop over the dataset multiple times\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    best_criterion = 0\n",
    "    \n",
    "    ## model in training mode\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        pred = torch.argmax(outputs,dim=1)\n",
    "       \n",
    "        num_correct = (pred==labels).sum().item()\n",
    "        train_acc += num_correct/inputs.size()[0]\n",
    "   \n",
    "    \n",
    "    val_acc = 0\n",
    "    \n",
    "    ## model in evaluation mode\n",
    "    model.eval()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            pred = torch.argmax(outputs,dim=1)\n",
    "       \n",
    "            num_correct = (pred==labels).sum().item()\n",
    "        \n",
    "            val_acc += num_correct/inputs.size()[0]\n",
    "            \n",
    "    print(\"Epoch:{} Train Loss:{:.2f} Train Accuracy:{:.2f} Val Accuracy:{:.2f}\".format(epoch,train_loss/len(train_loader),(train_acc/len(train_loader))*100,(val_acc/len(valid_loader))*100))\n",
    "    \n",
    "    if val_acc > best_criterion:\n",
    "        torch.save(model.state_dict(),\"./{}_model_best.pth.tar\".format(model_arch))\n",
    "        \n",
    "    \n",
    "    best_criterion = max(best_criterion,val_acc)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_arch == \"mlp\":\n",
    "    model = model = MLP((48,48),7)\n",
    "elif model_arch == \"cnn_net\":\n",
    "    model = CNN_Net()\n",
    "\n",
    "model.load_state_dict(torch.load(\"./{}_model_best.pth.tar\".format(model_arch)))\n",
    "model.eval()\n",
    "\n",
    "test_acc = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        pred = torch.argmax(outputs,dim=1)\n",
    "\n",
    "        num_correct = (pred==labels).sum().item()\n",
    "\n",
    "        test_acc += num_correct/inputs.size()[0]\n",
    "\n",
    "print(\"Test Accuracy: {:.2f}\".format((test_acc/len(test_loader))*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6312f1",
   "metadata": {},
   "source": [
    "## This performance can be further improved by transfer learning which will be explained in detailed in the upcoming tutorial. Stay tuned !!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
