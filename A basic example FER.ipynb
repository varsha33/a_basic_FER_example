{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6806fb7",
   "metadata": {},
   "source": [
    "# In this tutorial we will be building two facial expression classifiers from a labelled dataset FER2013. We will be using a Multi-Layer perceptron model (MLP) and CNN-based model to perform the classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06bbdd5",
   "metadata": {},
   "source": [
    "## Install necessary python packages \n",
    "\n",
    "Run the below commands if these packages are not installed in your system. \n",
    "\n",
    "- pip install pandas\n",
    "- pip install torch\n",
    "- pip install -U scikit-learn\n",
    "\n",
    "For visualisation\n",
    "\n",
    "- pip install matplotlib\n",
    "- pip install seaborn\n",
    "\n",
    "You can also use conda to install the packages.\n",
    "\n",
    "## Obtaining the data \n",
    "Download the data from the below link (icml_face_data.csv) and save it in the project folder </br>  \n",
    "https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data?select=icml_face_data.csv\n",
    "\n",
    "\n",
    "\n",
    "## Credits\n",
    "\n",
    "https://www.kaggle.com/alinaspasskaya/lab-2-face-emotion-classification-with-mlp </br>\n",
    "https://www.kaggle.com/sharadhaviswanathan/imageclassification-facialexpression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cefc19b",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4240d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "## torch packages\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2538a4",
   "metadata": {},
   "source": [
    "## Obtaining and Preprocessing the data\n",
    "\n",
    "In data preparation the first step will be getting the train, validation and test data and this applies across all the modalities.Preprocessing the dataset varies based on both dataset and the model architecture in place. For example, some model architecture requries certain image dimensions. \n",
    "\n",
    "\n",
    "####  Currently this code does not involve much preprocessing. We will cover some in the upcoming tutorial. Some of the recommended methods that you can check out are to further improve the model are,\n",
    "\n",
    "1. Random data augmentation (to help generalisability of the model)\n",
    "2. Oversampling or Undersampling the data to makeup for the imbalance in the data (visualizing the class distribution can help)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454051c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/icml_face_data.csv\"\n",
    "data = pd.read_csv(data_path) ## Grayscale images\n",
    "\n",
    "# (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral).\n",
    "emotion_labels = ['Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise', 'Neutral']\n",
    "\n",
    "\n",
    "def parse_data(data):\n",
    "    \n",
    "    image_array = np.zeros(shape=(len(data), 48, 48)) # 1\n",
    "    image_label = np.array(list(map(int, data['emotion']))) \n",
    "    \n",
    "    for i, row in enumerate(data.index):\n",
    "        \n",
    "        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48)) # 1\n",
    "        image_array[i] = image\n",
    "        \n",
    "        \n",
    "    return image_array, image_label\n",
    "\n",
    "# Splitting the data into train, validation and testing set thanks to Usage column\n",
    "train_imgs, train_lbls = parse_data(data[data[\" Usage\"] == \"Training\"])\n",
    "val_imgs, val_lbls = parse_data(data[data[\" Usage\"] == \"PublicTest\"])\n",
    "test_imgs, test_lbls = parse_data(data[data[\" Usage\"] == \"PrivateTest\"])\n",
    "\n",
    "\n",
    "\n",
    "def sample_plot(x,y=None):    #x, y are numpy arrays\n",
    "    n = 10 ## number of images to show\n",
    "    samples = random.sample(range(x.shape[0]),n)\n",
    "    fig, axs = plt.subplots(2,5, figsize=(25,5))\n",
    "    ax = axs.ravel()\n",
    "    for i in range(n):\n",
    "        ax[i].imshow(x[samples[i],:,:], cmap=plt.get_cmap('gray'))\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_yticks([])\n",
    "        if y is not None:\n",
    "            ax[i].set_title(emotion_labels[y[samples[i]]])\n",
    "\n",
    "sample_plot(train_imgs,train_lbls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca95a9",
   "metadata": {},
   "source": [
    "## Structuring the dataset to pass it through a dataloader in Pytorch\n",
    "\n",
    "The below code creates a custom Pytorch dataset which helps the dataloader to access the data to create the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FER2013_Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,imgs,labels):\n",
    "\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img = torch.FloatTensor(self.imgs[index])\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "\n",
    "    \n",
    "train_dataset = FER2013_Dataset(train_imgs, train_lbls)\n",
    "valid_dataset = FER2013_Dataset(val_imgs, val_lbls)\n",
    "test_dataset = FER2013_Dataset(test_imgs, test_lbls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d61f583",
   "metadata": {},
   "source": [
    "## Defining the model architecture - A simple Neural Network\n",
    "\n",
    "Below Multi-Layer Perceptron (MLP) comprises of two dense layers with ReLU activation and an output layer. The input image of size 48 x 48 is flattened to form the input to the model. Please refer to the code for the dimension detail of each layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47fe9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    # define model layers\n",
    "    def __init__(self,img_size,output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.flatten_img_size = img_size[0]*img_size[1]\n",
    "        self.flatten_fc = nn.Linear(self.flatten_img_size,120)\n",
    "        self.fc1 = nn.Linear(120,84)\n",
    "        self.output_layer = nn.Linear(84,output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, img):\n",
    "        img = img.view(-1,self.flatten_img_size) ## img size: Batch size x 48 x 48 --> Batch size x 2304\n",
    "        \n",
    "        embedding = self.flatten_fc(img) ## Batch size x 2304 --> Batch size x 120\n",
    "        \n",
    "        embedding = F.relu(embedding) ## Applying non-linear activation after a dense layer\n",
    "        \n",
    "        embedding =  F.relu(self.fc1(embedding))  ## Batch size x  120--> Batch size x 84\n",
    "        \n",
    "        logits =  self.output_layer(embedding)    ## Batch size x 84 --> Batch size x output size\n",
    "         \n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3422ad98",
   "metadata": {},
   "source": [
    "## Defining the model architecture - A basic CNN classifier\n",
    "\n",
    "Below CNN Model have two 2D convolution with maxpooling layers. The output of which is flattened to pass through dense layers to get the output. The dimension details of these layers are provided in the code. Please refer to  https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html for understanding the input and output sizes with different settings of kernel sizes and strides. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN_Net, self).__init__()\n",
    "\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1,6,3) ## in channel, out channel = 6, kernel size = 3x3\n",
    "        self.maxpool1 =  nn.MaxPool2d(2) ## (kernel = 2x2 and default stride = 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(6,16,4) ## in channel, out channel = 16, kernel size = 4x4\n",
    "        self.maxpool2 =  nn.MaxPool2d(2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16*10*10, 120) ## out channel x height x width after convolution and pooling layers\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.output_layer = nn.Linear(84, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.unsqueeze(1) ## x : Batch size x 1 x 48 x 48\n",
    "        \n",
    "        # Conv2d : (h_out = h_in + kernel_size[0] -1), (w_out = w_in + kernel_size[1] -1), default stride = 1\n",
    "        \n",
    "        x = F.relu(self.conv1(x)) ## x : Batch size x 6 x 46 x 46\n",
    "\n",
    "        x = self.maxpool1(x) ## x : Batch size x 6 x 23 x 23   \n",
    "\n",
    "        x = F.relu(self.conv2(x))  ## x : Batch size x 6 x 20 x 20   \n",
    "        \n",
    "        x = self.maxpool2(x) ## x : Batch size x 16 x 10 x 10 \n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten, x : Batch size x 1600 \n",
    "\n",
    "        x = F.relu(self.fc1(x)) # x : Batch size x 120\n",
    "        \n",
    "        x = F.relu(self.fc2(x)) # x : Batch size x 84 \n",
    "        \n",
    "        x = self.output_layer(x) # x : Batch size x 7\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac56e13",
   "metadata": {},
   "source": [
    " <font color='red'> <b> >> CHANGE THE PARAMETERS IN THE BELOW CELL</font>\n",
    "\n",
    "## Getting things ready for training\n",
    "\n",
    "A fairly general checklist,\n",
    "\n",
    "1. Parmeter settings\n",
    "2. Choose the model\n",
    "3. Initialise the data loaders using the created dataset\n",
    "4. Loss function\n",
    "5. Optimiser\n",
    "6. Learning rate scheduler (You can try adding this)\n",
    "\n",
    "Please set the random seed to help get same results for every run in a particular machnine. \n",
    "    \n",
    "###### Do note that the choice of the items in this checklist is highly dependant on your choice of task, model and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3731b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SET THE SEED FOR GETTING THE SAME RESULTS AGAIN\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "## Parameter settings\n",
    "nepoch = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "model_arch = \"cnn_net\"\n",
    "output_size = len(emotion_labels)\n",
    "\n",
    "# MODEL\n",
    "if model_arch == \"mlp\":\n",
    "    model = MLP((48,48),output_size) ## 48x48 is the input size of FER2013 dataset\n",
    "elif model_arch == \"cnn_net\":\n",
    "    model = CNN_Net()\n",
    "    \n",
    "\n",
    "# DATA LOADER\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = batch_size,shuffle= True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,batch_size = 1,shuffle= False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size = 1,shuffle= False)\n",
    "\n",
    "# LOSS\n",
    "loss_fn = nn.CrossEntropyLoss()  ## applies softmax to the logits before computing the loss \n",
    "\n",
    "\n",
    "# OPTIMISER\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9015fbba",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The training dataset is divided into batches by the dataloader. The weights of the model are updated after learning every batch. Here, we choose the best model based on the validation performance (accuracy). The best validation accuracy for MLP model comes around ~33% and for CNN Model around ~49% . </br>\n",
    "\n",
    "Currently the model is ran for \"nepoch\" number of times, early stopping can be employed to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27905e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(nepoch):  # loop over the dataset multiple times\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    best_criterion = 0\n",
    "    \n",
    "    ## model in training mode\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        inputs, target = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        pred = torch.argmax(outputs,dim=1)\n",
    "       \n",
    "        num_correct = (pred==target).sum().item()\n",
    "        train_acc += num_correct/inputs.size()[0]\n",
    "   \n",
    "    \n",
    "    val_acc = 0\n",
    "    val_loss = 0\n",
    "    ## model in evaluation mode\n",
    "    model.eval()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, target = data\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, target)\n",
    "            \n",
    "            pred = torch.argmax(outputs,dim=1)\n",
    "       \n",
    "            num_correct = (pred==target).sum().item()\n",
    "            \n",
    "            val_acc += num_correct/inputs.size()[0]\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    print(\"Epoch:{} Train Loss:{:.2f} Train Accuracy:{:.2f} Val Loss:{:.2f} Val Accuracy:{:.2f}\".format(epoch,train_loss/len(train_loader),(train_acc/len(train_loader))*100,val_loss/len(valid_loader),(val_acc/len(valid_loader))*100))\n",
    "    \n",
    "    if val_acc > best_criterion:\n",
    "        torch.save(model.state_dict(),\"./{}_model_best.pth.tar\".format(model_arch))\n",
    "\n",
    "    best_criterion = max(best_criterion,val_acc)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c977b3",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "In the testing phase,the weights of the best model from the training phase is loaded to get the evaluation performance on the test dataset. The best validation accuracy for MLP model comes around ~28% and for CNN Model around ~47%. </br>\n",
    "\n",
    "We also measure the weighted F1 score, we use the weighted version due imbalance in the class distribution. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_arch == \"mlp\":\n",
    "    model = model = MLP((48,48),output_size)\n",
    "elif model_arch == \"cnn_net\":\n",
    "    model = CNN_Net()\n",
    "\n",
    "\n",
    "conf_matrix = torch.zeros(output_size,output_size) ## CONFUSION MATRIX\n",
    "total_num_samples = torch.zeros(output_size) ## KEEPS COUNT OF TOTAL NUMBER OF SAMPLES PER CLASS\n",
    "\n",
    "model.load_state_dict(torch.load(\"./{}_model_best.pth.tar\".format(model_arch)))\n",
    "model.eval()\n",
    "\n",
    "test_acc = 0\n",
    "total = 0\n",
    "y_pred,y_true = [],[]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, target = data\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        pred = torch.argmax(outputs,dim=1)\n",
    "\n",
    "        num_correct = (pred==target).sum().item()\n",
    "\n",
    "        test_acc += num_correct/inputs.size()[0]\n",
    "        \n",
    "\n",
    "        for t, p in zip(target.data, pred):\n",
    "            conf_matrix[t.long(), p.long()] += 1\n",
    "            total_num_samples[t.long()] +=1\n",
    "    \n",
    "        y_pred.extend(pred.tolist())\n",
    "        y_true.extend(target.data.tolist())\n",
    "            \n",
    "## Weighted F1 score calculation\n",
    "test_f1 = f1_score(y_true, y_pred, labels=list(range(0,output_size)),average='weighted')\n",
    "\n",
    "print(\"Test Accuracy: {:.2f} Test F1: {:.2f}\".format((test_acc/len(test_loader))*100,(test_f1)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e2a8e",
   "metadata": {},
   "source": [
    "## Visualisation : Confusion matrix\n",
    "\n",
    "Confusion matrix helps visualise the misclassifications amongst the classes. Here, the confusion matrix is normalised by dividing each row with total number of samples in the class represented by the row. The diagonals of the matrix gives the per class accuracy of each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ec44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as  sns\n",
    "\n",
    "## NORMALISING THE CONFUSION MATRIX\n",
    "normalised_conf_matrix = torch.div(conf_matrix,total_num_samples.unsqueeze(-1)) \n",
    "\n",
    "ticklabels = emotion_labels\n",
    "sns.heatmap(normalised_conf_matrix,annot=True, fmt=\".2f\",xticklabels=ticklabels,yticklabels=ticklabels,cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted class\")\n",
    "plt.ylabel(\"True class\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6312f1",
   "metadata": {},
   "source": [
    "## This performance can be further improved by transfer learning which will be explained in detailed in the upcoming tutorial. Stay tuned !!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
